{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Dieses Notebook ist Teil des Grundprojekts \"enchmarking von Retrievalmethoden in RAG-Systemen: Ein Vergleich zwischen Vektor- und Graph-basiertem Retrieval\".\n",
    "Ziel ist die Vorbereitung des Datenmaterials für die Experimente mit Vektor- und Graph-Retrieval. Grundlage bilden 15 FAQ-Dokumente mit Fragen und Antworten.\n",
    "Vgl. Gao et al. (2023) für RAG-Grundlagen und Sarmah et al. (2023) für Graph-Retrieval."
   ],
   "id": "ebacfe969bbe564a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-10T17:45:56.074612Z",
     "start_time": "2025-08-10T17:45:50.143075Z"
    }
   },
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T17:45:56.099391Z",
     "start_time": "2025-08-10T17:45:56.091025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "faq_documents = [\n",
    "    {\n",
    "        \"id\": \"doc_001\",\n",
    "        \"question\": \"Was ist Retrieval-Augmented Generation (RAG)?\",\n",
    "        \"answer\": \"RAG ist eine Technik, die Large Language Models mit externen Wissensquellen verbindet. Das Modell kann relevante Informationen aus einer Wissensbasis abrufen und diese in seine Antworten einbeziehen. Dies reduziert Halluzinationen und ermöglicht aktuellere Informationen.\",\n",
    "        \"category\": \"RAG Basics\",\n",
    "        \"keywords\": [\"RAG\", \"retrieval\", \"language model\", \"knowledge base\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_002\",\n",
    "        \"question\": \"Wie funktioniert Vektorsuche in RAG-Systemen?\",\n",
    "        \"answer\": \"Bei der Vektorsuche werden Dokumente und Anfragen in hochdimensionale Vektoren (Embeddings) umgewandelt. Die Ähnlichkeit wird durch Cosinus-Ähnlichkeit oder andere Metriken gemessen. FAISS oder ähnliche Bibliotheken ermöglichen schnelle Suche in großen Vektorräumen.\",\n",
    "        \"category\": \"Vector Retrieval\",\n",
    "        \"keywords\": [\"vector search\", \"embeddings\", \"FAISS\", \"similarity\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_003\",\n",
    "        \"question\": \"Was sind die Vorteile von Graph-basiertem Retrieval?\",\n",
    "        \"answer\": \"Graph-basiertes Retrieval kann Beziehungen zwischen Entitäten erfassen und komplexe, multi-hop Reasoning ermöglichen. Es ist besonders stark bei strukturierten Daten und kann Kontext durch Graphtraversierung liefern. Knowledge Graphs bieten explizite semantische Beziehungen.\",\n",
    "        \"category\": \"Graph Retrieval\",\n",
    "        \"keywords\": [\"graph retrieval\", \"knowledge graph\", \"relationships\", \"reasoning\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_004\",\n",
    "        \"question\": \"Welche Evaluationsmetriken gibt es für RAG-Systeme?\",\n",
    "        \"answer\": \"Häufige Metriken sind BLEU und ROUGE für Textähnlichkeit, sowie Faithfulness und Answer Relevancy. GPT-as-a-Judge wird oft für qualitative Bewertung genutzt. Retrieval-Metriken wie Precision@K und Recall@K messen die Qualität der abgerufenen Dokumente.\",\n",
    "        \"category\": \"Evaluation\",\n",
    "        \"keywords\": [\"BLEU\", \"ROUGE\", \"evaluation\", \"metrics\", \"GPT-judge\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_005\",\n",
    "        \"question\": \"Was ist der Unterschied zwischen Dense und Sparse Retrieval?\",\n",
    "        \"answer\": \"Dense Retrieval nutzt neuronale Embeddings für semantische Ähnlichkeit, während Sparse Retrieval auf exakte Keyword-Matches setzt (wie BM25). Dense Retrieval ist besser für semantische Suche, Sparse Retrieval für exakte Begriff-Suche. Hybrid-Ansätze kombinieren beide.\",\n",
    "        \"category\": \"Retrieval Methods\",\n",
    "        \"keywords\": [\"dense retrieval\", \"sparse retrieval\", \"BM25\", \"embeddings\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_006\",\n",
    "        \"question\": \"Wie wählt man die richtige Chunk-Größe für RAG?\",\n",
    "        \"answer\": \"Die Chunk-Größe hängt vom Use Case ab. Kleine Chunks (100-200 Tokens) bieten präzise Retrieval, große Chunks (500-1000 Tokens) mehr Kontext. Overlap zwischen Chunks verhindert Informationsverlust. Experimentierung mit verschiedenen Größen ist empfohlen.\",\n",
    "        \"category\": \"Data Processing\",\n",
    "        \"keywords\": [\"chunking\", \"token size\", \"overlap\", \"preprocessing\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_007\",\n",
    "        \"question\": \"Was sind häufige Probleme bei RAG-Implementierungen?\",\n",
    "        \"answer\": \"Häufige Probleme sind: irrelevante Retrieval-Ergebnisse, Halluzinationen trotz RAG, hohe Latenz, Context-Window-Überschreitungen und schlechte Chunk-Qualität. Lösungen umfassen bessere Embeddings, Re-ranking, und optimierte Chunk-Strategien.\",\n",
    "        \"category\": \"Troubleshooting\",\n",
    "        \"keywords\": [\"problems\", \"hallucination\", \"latency\", \"context window\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_008\",\n",
    "        \"question\": \"Welche Rolle spielt LangChain in RAG-Systemen?\",\n",
    "        \"answer\": \"LangChain bietet einen einheitlichen Framework für RAG-Implementierungen. Es abstrahiert Retriever, Vector Stores und LLM-Integrationen. Chain-Komponenten ermöglichen modulare Pipelines. LangChain vereinfacht die Integration verschiedener Tools und Datenquellen.\",\n",
    "        \"category\": \"Tools\",\n",
    "        \"keywords\": [\"LangChain\", \"framework\", \"chains\", \"integration\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_009\",\n",
    "        \"question\": \"Wie funktioniert Re-ranking in RAG-Pipelines?\",\n",
    "        \"answer\": \"Re-ranking verbessert die initial abgerufenen Dokumente durch ein zweites Modell. Cross-encoder oder spezialisierte Re-ranking-Modelle bewerten Relevanz präziser als die erste Retrieval-Stufe. Dies kann die Antwortqualität signifikant verbessern.\",\n",
    "        \"category\": \"Advanced Techniques\",\n",
    "        \"keywords\": [\"re-ranking\", \"cross-encoder\", \"two-stage retrieval\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_010\",\n",
    "        \"question\": \"Was ist Hybrid Retrieval und wann sollte man es nutzen?\",\n",
    "        \"answer\": \"Hybrid Retrieval kombiniert verschiedene Retrieval-Methoden, typischerweise Dense und Sparse. Es nutzt die Stärken beider Ansätze: semantische Suche und exakte Keyword-Matches. Besonders effektiv bei diversen Query-Typen und großen Wissensbasen.\",\n",
    "        \"category\": \"Advanced Techniques\",\n",
    "        \"keywords\": [\"hybrid retrieval\", \"combination\", \"dense\", \"sparse\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_011\",\n",
    "        \"question\": \"Welche Vector Databases sind für RAG geeignet?\",\n",
    "        \"answer\": \"Beliebte Optionen sind Pinecone, Weaviate, Qdrant und Chroma für managed Services. FAISS eignet sich für lokale Implementierungen. Die Wahl hängt von Skalierung, Latenz-Anforderungen und Budget ab. PostgreSQL mit pgvector ist eine kostengünstige Alternative.\",\n",
    "        \"category\": \"Infrastructure\",\n",
    "        \"keywords\": [\"vector database\", \"Pinecone\", \"FAISS\", \"Chroma\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_012\",\n",
    "        \"question\": \"Wie optimiert man die Embedding-Qualität für RAG?\",\n",
    "        \"answer\": \"Fine-tuning von Embedding-Modellen auf domänenspezifische Daten verbessert Retrieval-Qualität. Auch die Wahl des Base-Models (OpenAI, Sentence-Transformers) ist wichtig. Preprocessing, Normalisierung und geeignete Similarity-Metriken spielen eine Rolle.\",\n",
    "        \"category\": \"Optimization\",\n",
    "        \"keywords\": [\"embeddings\", \"fine-tuning\", \"domain-specific\", \"similarity\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_013\",\n",
    "        \"question\": \"Was sind die Kosten-Überlegungen bei RAG-Systemen?\",\n",
    "        \"answer\": \"Hauptkostenfaktoren sind LLM-API-Calls, Vector-Database-Hosting und Embedding-Generierung. Caching von Embeddings und Antworten reduziert Kosten. Lokale Modelle können API-Kosten eliminieren, benötigen aber eigene Infrastruktur.\",\n",
    "        \"category\": \"Business\",\n",
    "        \"keywords\": [\"costs\", \"pricing\", \"API\", \"caching\", \"local models\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_014\",\n",
    "        \"question\": \"Wie implementiert man RAG mit Neo4j?\",\n",
    "        \"answer\": \"Neo4j ermöglicht Graph-basiertes RAG durch Cypher-Queries. Entitäten und Beziehungen werden extrahiert und als Graph gespeichert. Retrieval erfolgt durch Graphtraversierung statt Vektorsuche. Dies ermöglicht komplexere, beziehungsbasierte Abfragen.\",\n",
    "        \"category\": \"Graph Implementation\",\n",
    "        \"keywords\": [\"Neo4j\", \"Cypher\", \"graph traversal\", \"entities\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_015\",\n",
    "        \"question\": \"Welche Zukunftstrends gibt es bei RAG-Technologien?\",\n",
    "        \"answer\": \"Trends umfassen Agentic RAG mit Tool-Usage, Multi-modal RAG für Bilder/Videos, und Adaptive Retrieval basierend auf Query-Komplexität. Knowledge Graph-Integration wird wichtiger, ebenso Real-time Updates und personalisierte Retrieval-Strategien.\",\n",
    "        \"category\": \"Future Trends\",\n",
    "        \"keywords\": [\"agentic RAG\", \"multi-modal\", \"adaptive retrieval\", \"trends\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"FAQ-Korpus erstellt: {len(faq_documents)} Dokumente\")"
   ],
   "id": "d670ffcf1a5a3a52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAQ-Korpus erstellt: 15 Dokumente\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Testfragen erstellen\n",
    "\n",
    "12 Fragen verschiedener Schwierigkeitsgrade für das Benchmarking."
   ],
   "id": "fee73acb0746db02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T17:45:56.130055Z",
     "start_time": "2025-08-10T17:45:56.123153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testfragen für das Benchmarking\n",
    "test_questions = [\n",
    "    {\n",
    "        \"id\": \"q001\",\n",
    "        \"question\": \"Erkläre mir RAG in einfachen Worten\",\n",
    "        \"expected_topics\": [\"RAG\", \"retrieval\", \"language model\"],\n",
    "        \"difficulty\": \"easy\",\n",
    "        \"category\": \"basic\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"q002\",\n",
    "        \"question\": \"Was sind die Unterschiede zwischen Vektor- und Graph-Retrieval?\",\n",
    "        \"expected_topics\": [\"vector search\", \"graph retrieval\", \"comparison\"],\n",
    "        \"difficulty\": \"medium\",\n",
    "        \"category\": \"comparison\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"q003\",\n",
    "        \"question\": \"Welche Evaluationsmetriken sollte ich für mein RAG-System verwenden?\",\n",
    "        \"expected_topics\": [\"BLEU\", \"ROUGE\", \"evaluation\", \"metrics\"],\n",
    "        \"difficulty\": \"medium\",\n",
    "        \"category\": \"technical\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"q004\",\n",
    "        \"question\": \"Wie optimiere ich die Performance meines RAG-Systems?\",\n",
    "        \"expected_topics\": [\"optimization\", \"chunking\", \"embeddings\", \"re-ranking\"],\n",
    "        \"difficulty\": \"hard\",\n",
    "        \"category\": \"optimization\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"q005\",\n",
    "        \"question\": \"Was kostet der Betrieb eines RAG-Systems?\",\n",
    "        \"expected_topics\": [\"costs\", \"pricing\", \"infrastructure\"],\n",
    "        \"difficulty\": \"easy\",\n",
    "        \"category\": \"business\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"q006\",\n",
    "        \"question\": \"Wie implementiere ich Hybrid Retrieval?\",\n",
    "        \"expected_topics\": [\"hybrid retrieval\", \"dense\", \"sparse\", \"combination\"],\n",
    "        \"difficulty\": \"hard\",\n",
    "        \"category\": \"technical\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"q007\",\n",
    "        \"question\": \"Welche Vector Database sollte ich wählen?\",\n",
    "        \"expected_topics\": [\"vector database\", \"FAISS\", \"Pinecone\"],\n",
    "        \"difficulty\": \"medium\",\n",
    "        \"category\": \"infrastructure\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"q008\",\n",
    "        \"question\": \"Was sind häufige Probleme bei RAG und wie löse ich sie?\",\n",
    "        \"expected_topics\": [\"problems\", \"troubleshooting\", \"hallucination\"],\n",
    "        \"difficulty\": \"medium\",\n",
    "        \"category\": \"troubleshooting\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"q009\",\n",
    "        \"question\": \"Wie funktioniert RAG mit Knowledge Graphs?\",\n",
    "        \"expected_topics\": [\"Neo4j\", \"knowledge graph\", \"Cypher\"],\n",
    "        \"difficulty\": \"hard\",\n",
    "        \"category\": \"graph\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"q010\",\n",
    "        \"question\": \"Was ist der optimale Chunk-Size für meine Dokumente?\",\n",
    "        \"expected_topics\": [\"chunking\", \"token size\", \"preprocessing\"],\n",
    "        \"difficulty\": \"medium\",\n",
    "        \"category\": \"preprocessing\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"q011\",\n",
    "        \"question\": \"Welche Zukunftstrends gibt es bei RAG?\",\n",
    "        \"expected_topics\": [\"future trends\", \"agentic RAG\", \"multi-modal\"],\n",
    "        \"difficulty\": \"easy\",\n",
    "        \"category\": \"trends\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"q012\",\n",
    "        \"question\": \"Wie verbessere ich meine Embedding-Qualität?\",\n",
    "        \"expected_topics\": [\"embeddings\", \"fine-tuning\", \"optimization\"],\n",
    "        \"difficulty\": \"hard\",\n",
    "        \"category\": \"optimization\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Testfragen erstellt: {len(test_questions)} Fragen\")\n",
    "print(f\"   - Easy: {len([q for q in test_questions if q['difficulty'] == 'easy'])}\")\n",
    "print(f\"   - Medium: {len([q for q in test_questions if q['difficulty'] == 'medium'])}\")\n",
    "print(f\"   - Hard: {len([q for q in test_questions if q['difficulty'] == 'hard'])}\")"
   ],
   "id": "412b2a48aa9128da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testfragen erstellt: 12 Fragen\n",
      "   - Easy: 3\n",
      "   - Medium: 5\n",
      "   - Hard: 4\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Daten speichern"
   ],
   "id": "c244722fee6fb95b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T17:48:49.036803Z",
     "start_time": "2025-08-10T17:48:49.031833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"../data/faq_korpus.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(faq_documents, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"FAQ-Korpus gespeichert: ../data/faq_korpus.json\")"
   ],
   "id": "fae0f6f22c0cd6ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAQ-Korpus gespeichert: ../data/faq_corpus.json\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T17:48:56.007451Z",
     "start_time": "2025-08-10T17:48:55.942476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testfragen als CSV speichern (für bessere Übersicht)\n",
    "questions_df = pd.DataFrame(test_questions)\n",
    "questions_df.to_csv('../data/fragenliste.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Testfragen gespeichert: ../data/fragenliste.csv\")\n",
    "print(\"\\nÜbersicht der Testfragen:\")\n",
    "display(questions_df[['id', 'question', 'difficulty', 'category']])"
   ],
   "id": "b4888594988bcd23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testfragen gespeichert: ../data/fragenliste.csv\n",
      "\n",
      "Übersicht der Testfragen:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      id                                           question difficulty  \\\n",
       "0   q001                Erkläre mir RAG in einfachen Worten       easy   \n",
       "1   q002  Was sind die Unterschiede zwischen Vektor- und...     medium   \n",
       "2   q003  Welche Evaluationsmetriken sollte ich für mein...     medium   \n",
       "3   q004  Wie optimiere ich die Performance meines RAG-S...       hard   \n",
       "4   q005          Was kostet der Betrieb eines RAG-Systems?       easy   \n",
       "5   q006            Wie implementiere ich Hybrid Retrieval?       hard   \n",
       "6   q007          Welche Vector Database sollte ich wählen?     medium   \n",
       "7   q008  Was sind häufige Probleme bei RAG und wie löse...     medium   \n",
       "8   q009         Wie funktioniert RAG mit Knowledge Graphs?       hard   \n",
       "9   q010  Was ist der optimale Chunk-Size für meine Doku...     medium   \n",
       "10  q011             Welche Zukunftstrends gibt es bei RAG?       easy   \n",
       "11  q012       Wie verbessere ich meine Embedding-Qualität?       hard   \n",
       "\n",
       "           category  \n",
       "0             basic  \n",
       "1        comparison  \n",
       "2         technical  \n",
       "3      optimization  \n",
       "4          business  \n",
       "5         technical  \n",
       "6    infrastructure  \n",
       "7   troubleshooting  \n",
       "8             graph  \n",
       "9     preprocessing  \n",
       "10           trends  \n",
       "11     optimization  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q001</td>\n",
       "      <td>Erkläre mir RAG in einfachen Worten</td>\n",
       "      <td>easy</td>\n",
       "      <td>basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q002</td>\n",
       "      <td>Was sind die Unterschiede zwischen Vektor- und...</td>\n",
       "      <td>medium</td>\n",
       "      <td>comparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q003</td>\n",
       "      <td>Welche Evaluationsmetriken sollte ich für mein...</td>\n",
       "      <td>medium</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q004</td>\n",
       "      <td>Wie optimiere ich die Performance meines RAG-S...</td>\n",
       "      <td>hard</td>\n",
       "      <td>optimization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q005</td>\n",
       "      <td>Was kostet der Betrieb eines RAG-Systems?</td>\n",
       "      <td>easy</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>q006</td>\n",
       "      <td>Wie implementiere ich Hybrid Retrieval?</td>\n",
       "      <td>hard</td>\n",
       "      <td>technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>q007</td>\n",
       "      <td>Welche Vector Database sollte ich wählen?</td>\n",
       "      <td>medium</td>\n",
       "      <td>infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>q008</td>\n",
       "      <td>Was sind häufige Probleme bei RAG und wie löse...</td>\n",
       "      <td>medium</td>\n",
       "      <td>troubleshooting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>q009</td>\n",
       "      <td>Wie funktioniert RAG mit Knowledge Graphs?</td>\n",
       "      <td>hard</td>\n",
       "      <td>graph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>q010</td>\n",
       "      <td>Was ist der optimale Chunk-Size für meine Doku...</td>\n",
       "      <td>medium</td>\n",
       "      <td>preprocessing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>q011</td>\n",
       "      <td>Welche Zukunftstrends gibt es bei RAG?</td>\n",
       "      <td>easy</td>\n",
       "      <td>trends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>q012</td>\n",
       "      <td>Wie verbessere ich meine Embedding-Qualität?</td>\n",
       "      <td>hard</td>\n",
       "      <td>optimization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Überblick der erstellten Daten"
   ],
   "id": "39f8dd3a77a8f06b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T17:49:29.726102Z",
     "start_time": "2025-08-10T17:49:29.718406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Übersicht FAQ-Korpus\n",
    "print(\"=== FAQ-KORPUS ÜBERSICHT ===\")\n",
    "print(f\"Anzahl Dokumente: {len(faq_documents)}\")\n",
    "\n",
    "# Kategorien anzeigen\n",
    "categories = [doc['category'] for doc in faq_documents]\n",
    "category_counts = pd.Series(categories).value_counts()\n",
    "print(\"\\nKategorien:\")\n",
    "for cat, count in category_counts.items():\n",
    "    print(f\"  - {cat}: {count} Dokumente\")\n",
    "\n",
    "# Beispiel-Dokument\n",
    "print(\"\\n=== BEISPIEL-DOKUMENT ===\")\n",
    "example = faq_documents[0]\n",
    "print(f\"ID: {example['id']}\")\n",
    "print(f\"Frage: {example['question']}\")\n",
    "print(f\"Antwort: {example['answer'][:100]}...\")\n",
    "print(f\"Keywords: {example['keywords']}\")"
   ],
   "id": "77d258282d0ef69e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FAQ-KORPUS ÜBERSICHT ===\n",
      "Anzahl Dokumente: 15\n",
      "\n",
      "Kategorien:\n",
      "  - Advanced Techniques: 2 Dokumente\n",
      "  - RAG Basics: 1 Dokumente\n",
      "  - Graph Retrieval: 1 Dokumente\n",
      "  - Evaluation: 1 Dokumente\n",
      "  - Retrieval Methods: 1 Dokumente\n",
      "  - Vector Retrieval: 1 Dokumente\n",
      "  - Data Processing: 1 Dokumente\n",
      "  - Troubleshooting: 1 Dokumente\n",
      "  - Tools: 1 Dokumente\n",
      "  - Infrastructure: 1 Dokumente\n",
      "  - Optimization: 1 Dokumente\n",
      "  - Business: 1 Dokumente\n",
      "  - Graph Implementation: 1 Dokumente\n",
      "  - Future Trends: 1 Dokumente\n",
      "\n",
      "=== BEISPIEL-DOKUMENT ===\n",
      "ID: doc_001\n",
      "Frage: Was ist Retrieval-Augmented Generation (RAG)?\n",
      "Antwort: RAG ist eine Technik, die Large Language Models mit externen Wissensquellen verbindet. Das Modell ka...\n",
      "Keywords: ['RAG', 'retrieval', 'language model', 'knowledge base']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T17:49:38.030337Z",
     "start_time": "2025-08-10T17:49:38.026601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n=== SETUP ABGESCHLOSSEN ===\")\n",
    "print(\"FAQ-Korpus: 15 Dokumente erstellt\")\n",
    "print(\"Testfragen: 12 Fragen formuliert\")\n",
    "print(\"Dateien gespeichert in /data/\")"
   ],
   "id": "98313bac929147fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SETUP ABGESCHLOSSEN ===\n",
      "FAQ-Korpus: 15 Dokumente erstellt\n",
      "Testfragen: 12 Fragen formuliert\n",
      "Dateien gespeichert in /data/\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
